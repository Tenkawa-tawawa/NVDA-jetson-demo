# Jetson Orin 程式實作專案 (2)

這個學習資源旨在讓你體驗 **CUDA 平行運算** 在 Jetson Orin 上的開發流程。你將學會如何撰寫 `CUDA kernel`、配置 `threads/blocks`，並觀察 GPU 的效能表現，進一步理解 **CUDA 加速原理**。

## 準備環境

確認系統已安裝 CUDA Toolkit（JetPack 已內建）。

```bash
nvcc --version
```
建立一個新的專案資料夾，準備撰寫 .cu 檔案。


## 編譯與執行

1. 使用 `nvcc` 編譯 CUDA 程式：

```bash
nvcc vector_add.cu -o vector_add
```
2. 執行程式：

```bash
./vector_add
```
3. 啟動效能監測（Nsight Systems）：
```bash
nsys profile ./vector_add
```

## 進階練習題

1. 向量加法 CUDA kernel
  * 撰寫一個 kernel 完成 C = A + B
  * 比較 CPU 與 GPU 的執行時間差異
2. 矩陣乘法 CUDA kernel
  * 撰寫一個 kernel 完成 C = A × B
  * 嘗試不同的 threads/blocks 配置，觀察效能差異
3. 延伸挑戰：混合精度運算
  * 將矩陣乘法改用 float 與 half 精度
  * 比較效能與結果精度的差異


## 範例解答
### vector_add.cu
```cpp
#include <iostream>
#include <cuda_runtime.h>
using namespace std;

__global__ void vectorAdd(const float* A, const float* B, float* C, int N) {
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i < N) C[i] = A[i] + B[i];
}

int main() {
    int N = 1<<20;
    size_t size = N * sizeof(float);
    float *h_A = new float[N], *h_B = new float[N], *h_C = new float[N];
    for(int i=0;i<N;i++){ h_A[i]=1.0f; h_B[i]=2.0f; }

    float *d_A,*d_B,*d_C;
    cudaMalloc(&d_A,size); cudaMalloc(&d_B,size); cudaMalloc(&d_C,size);
    cudaMemcpy(d_A,h_A,size,cudaMemcpyHostToDevice);
    cudaMemcpy(d_B,h_B,size,cudaMemcpyHostToDevice);

    int threadsPerBlock=256;
    int blocksPerGrid=(N+threadsPerBlock-1)/threadsPerBlock;
    vectorAdd<<<blocksPerGrid,threadsPerBlock>>>(d_A,d_B,d_C,N);

    cudaMemcpy(h_C,d_C,size,cudaMemcpyDeviceToHost);
    cout<<"C[0]="<<h_C[0]<<endl;

    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);
    delete[] h_A; delete[] h_B; delete[] h_C;
}

```
### matrix_mul.cu
```cpp
#include <iostream>
#include <cuda_runtime.h>
using namespace std;

__global__ void matMul(const float* A,const float* B,float* C,int N){
    int row=blockIdx.y*blockDim.y+threadIdx.y;
    int col=blockIdx.x*blockDim.x+threadIdx.x;
    if(row<N && col<N){
        float sum=0;
        for(int k=0;k<N;k++) sum+=A[row*N+k]*B[k*N+col];
        C[row*N+col]=sum;
    }
}

int main(){
    int N=256; size_t size=N*N*sizeof(float);
    float *h_A=new float[N*N],*h_B=new float[N*N],*h_C=new float[N*N];
    for(int i=0;i<N*N;i++){ h_A[i]=1.0f; h_B[i]=2.0f; }

    float *d_A,*d_B,*d_C;
    cudaMalloc(&d_A,size); cudaMalloc(&d_B,size); cudaMalloc(&d_C,size);
    cudaMemcpy(d_A,h_A,size,cudaMemcpyHostToDevice);
    cudaMemcpy(d_B,h_B,size,cudaMemcpyHostToDevice);

    dim3 threadsPerBlock(16,16);
    dim3 blocksPerGrid((N+15)/16,(N+15)/16);
    matMul<<<blocksPerGrid,threadsPerBlock>>>(d_A,d_B,d_C,N);

    cudaMemcpy(h_C,d_C,size,cudaMemcpyDeviceToHost);
    cout<<"C[0]="<<h_C[0]<<endl;

    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);
    delete[] h_A; delete[] h_B; delete[] h_C;
}
```
### cublas_gemm.cu
```cpp
#include <iostream>
#include <cublas_v2.h>
#include <cuda_runtime.h>
using namespace std;

int main(){
    int N=256; size_t size=N*N*sizeof(float);
    float *A,*B,*C;
    cudaMallocManaged(&A,size); cudaMallocManaged(&B,size); cudaMallocManaged(&C,size);
    for(int i=0;i<N*N;i++){ A[i]=1.0f; B[i]=2.0f; }

    cublasHandle_t handle; cublasCreate(&handle);
    const float alpha=1.0f,beta=0.0f;
    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,N,N,N,&alpha,B,N,A,N,&beta,C,N);
    cudaDeviceSynchronize();

    cout<<"C[0]="<<C[0]<<endl;
    cublasDestroy(handle);
    cudaFree(A); cudaFree(B); cudaFree(C);
}
```
### cudnn_conv.cu
```cpp
#include <iostream>
#include <cudnn.h>
#include <cuda_runtime.h>
using namespace std;

int main(){
    cudnnHandle_t handle; cudnnCreate(&handle);
    cudnnTensorDescriptor_t xDesc,yDesc;
    cudnnFilterDescriptor_t wDesc;
    cudnnConvolutionDescriptor_t convDesc;
    cudnnCreateTensorDescriptor(&xDesc);
    cudnnCreateTensorDescriptor(&yDesc);
    cudnnCreateFilterDescriptor(&wDesc);
    cudnnCreateConvolutionDescriptor(&convDesc);

    cudnnSetTensor4dDescriptor(xDesc,CUDNN_TENSOR_NCHW,CUDNN_DATA_FLOAT,1,1,32,32);
    cudnnSetFilter4dDescriptor(wDesc,CUDNN_DATA_FLOAT,CUDNN_TENSOR_NCHW,1,1,3,3);
    cudnnSetConvolution2dDescriptor(convDesc,1,1,1,1,1,1,CUDNN_CROSS_CORRELATION,CUDNN_DATA_FLOAT);

    int n,c,h,w;
    cudnnGetConvolution2dForwardOutputDim(convDesc,xDesc,wDesc,&n,&c,&h,&w);
    cout<<"Output shape: "<<n<<"x"<<c<<"x"<<h<<"x"<<w<<endl;

    cudnnDestroyConvolutionDescriptor(convDesc);
    cudnnDestroyFilterDescriptor(wDesc);
    cudnnDestroyTensorDescriptor(xDesc);
    cudnnDestroyTensorDescriptor(yDesc);
    cudnnDestroy(handle);
}
```
